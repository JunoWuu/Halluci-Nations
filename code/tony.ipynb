{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general imports \n",
    "import os\n",
    "from pathlib import Path\n",
    "import hdmf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import pickle\n",
    "# nwb specific imports \n",
    "import pynwb\n",
    "from nwbwidgets import nwb2widget\n",
    "from hdmf_zarr import NWBZarrIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dont't need project_name\n",
    "# don't need date of birth, session date, session of time \n",
    "metadata = pd.read_csv('/home/tony/Halluci-Nations/data/metadata/npultra_metadata.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found filepath: /home/tony/Halluci-Nations/data/np-ultra-psychedelics/ecephys_714527_2024-05-14_13-22-07_nwb_2025-08-03_21-11-22/ecephys_714527_2024-05-14_13-22-07_experiment1_recording1.nwb\n"
     ]
    }
   ],
   "source": [
    "# Select psilocybin sessions \n",
    "filtered_metadata = metadata[metadata.session_type == 'saline']\n",
    "\n",
    "# Get the asset name \n",
    "session_name = filtered_metadata['name'].iloc[0]\n",
    "\n",
    "# Find the filepath \n",
    "data_dir = os.path.join(r'/home/tony/Halluci-Nations/data/np-ultra-psychedelics/', session_name)\n",
    "nwb_path_zarr = list(Path(data_dir).glob(\"*.nwb\"))[0]\n",
    "\n",
    "print('Found filepath:', nwb_path_zarr) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found filepath: /home/tony/Halluci-Nations/data/np-ultra-psychedelics/ecephys_714527_2024-05-15_13-00-23_nwb_2025-08-03_21-11-22/ecephys_714527_2024-05-15_13-00-23_experiment1_recording1.nwb\n"
     ]
    }
   ],
   "source": [
    "# Select psilocybin sessions \n",
    "filtered_metadata = metadata[metadata.session_type == 'psilocybin']\n",
    "\n",
    "# Get the asset name \n",
    "session_name = filtered_metadata['name'].iloc[0]\n",
    "\n",
    "# Find the filepath \n",
    "data_dir = os.path.join(r'/home/tony/Halluci-Nations/data/np-ultra-psychedelics/', session_name)\n",
    "nwb_path_zarr = list(Path(data_dir).glob(\"*.nwb\"))[0]\n",
    "\n",
    "print('Found filepath:', nwb_path_zarr) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found filepath: /home/tony/Halluci-Nations/data/np-ultra-psychedelics/ecephys_714527_2024-05-15_13-00-23_nwb_2025-08-03_21-11-22/ecephys_714527_2024-05-15_13-00-23_experiment1_recording1.nwb\n"
     ]
    }
   ],
   "source": [
    "# Select psilocybin sessions \n",
    "filtered_metadata = metadata[metadata.session_type == 'psilocybin']\n",
    "\n",
    "# Get the asset name \n",
    "session_name = filtered_metadata['name'].iloc[0]\n",
    "\n",
    "# Find the filepath \n",
    "data_dir = os.path.join(r'/home/tony/Halluci-Nations/data/np-ultra-psychedelics/', session_name)\n",
    "nwb_path_zarr = list(Path(data_dir).glob(\"*.nwb\"))[0]\n",
    "\n",
    "print('Found filepath:', nwb_path_zarr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util funtions template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'analysis_table'\n",
      "ecephys_714789_2024-05-17_11-47-07_nwb_2025-08-03_21-11-22\n"
     ]
    }
   ],
   "source": [
    "# Select psilocybin sessions \n",
    "filtered_metadata = metadata[metadata.session_type == 'saline']\n",
    "# Get the asset name \n",
    "session_names = filtered_metadata['name'].iloc[:]\n",
    "for session_name in session_names:\n",
    "    try:\n",
    "        data_dir = os.path.join(r'/home/tony/Halluci-Nations/data/np-ultra-psychedelics/', session_name)\n",
    "        nwb_path_zarr = list(Path(data_dir).glob(\"*.nwb\"))[0]\n",
    "        ##### extract relevent data for processing\n",
    "        save_path = f'/home/tony/Halluci-Nations/scratch/{session_name}'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "        io = NWBZarrIO(nwb_path_zarr, mode = 'r') \n",
    "        nwbfile_zarr = io.read()\n",
    "        df_analysis = nwbfile_zarr.analysis['analysis_table'].to_dataframe()\n",
    "        df_units = nwbfile_zarr.units.to_dataframe()\n",
    "        df_units['probe'] = df_units['device_name'].apply(lambda x: x.split('Probe')[1])\n",
    "        df_units = df_units[['ks_unit_id','probe','depth','estimated_x','estimated_y','estimated_z']]\n",
    "        df_units['ks_unit_id'] = [int(i) for i in df_units['ks_unit_id']]\n",
    "        df_data = df_analysis.merge(df_units,on = ['ks_unit_id','probe'])\n",
    "        df_data = df_data.sort_values(by=['region', 'layer'])\n",
    "        #df_data.to_csv(os.path.join(save_path,'data.csv'))\n",
    "        df_data.to_pickle(os.path.join(save_path,'data.pkl'))\n",
    "        df_epochs = nwbfile_zarr.stimulus['epochs'].to_dataframe()\n",
    "        df_photostim = nwbfile_zarr.stimulus['photostim'].to_dataframe()\n",
    "        df_visualstim = nwbfile_zarr.stimulus['visualstim'].to_dataframe()\n",
    "        #df_photostim.to_csv(os.path.join(save_path,'photostim.csv'))\n",
    "        #df_epochs.to_csv(os.path.join(save_path,'epochs.csv'))\n",
    "        #df_visualstim.to_csv(os.path.join(save_path,'visualstim.csv'))\n",
    "        df_data.to_pickle(os.path.join(save_path,'data.pkl'))\n",
    "        df_epochs.to_pickle(os.path.join(save_path,'epochs.pkl'))\n",
    "        df_photostim.to_pickle(os.path.join(save_path,'photostim.pkl'))\n",
    "        df_visualstim.to_pickle(os.path.join(save_path,'visualstim.pkl'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(session_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select psilocybin sessions \n",
    "filtered_metadata = metadata[metadata.session_type == 'saline']\n",
    "# Get the asset name \n",
    "session_names = filtered_metadata['name'].iloc[:]\n",
    "for session_name in session_names:\n",
    "    try:\n",
    "        data_dir = os.path.join(r'/home/tony/Halluci-Nations/data/np-ultra-psychedelics/', session_name)\n",
    "        nwb_path_zarr = list(Path(data_dir).glob(\"*.nwb\"))[0]\n",
    "        ##### extract relevent data for processing\n",
    "        save_path = f'/home/tony/Halluci-Nations/scratch/{session_name}'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "        io = NWBZarrIO(nwb_path_zarr, mode = 'r') \n",
    "        nwbfile_zarr = io.read()\n",
    "        df_analysis = nwbfile_zarr.analysis['analysis_table'].to_dataframe()\n",
    "        df_units = nwbfile_zarr.units.to_dataframe()\n",
    "        df_units['probe'] = df_units['device_name'].apply(lambda x: x.split('Probe')[1])\n",
    "        df_units = df_units[['ks_unit_id','probe','depth','estimated_x','estimated_y','estimated_z']]\n",
    "        df_units['ks_unit_id'] = [int(i) for i in df_units['ks_unit_id']]\n",
    "        df_data = df_analysis.merge(df_units,on = ['ks_unit_id','probe'])\n",
    "        df_data = df_data.sort_values(by=['region', 'layer'])\n",
    "        #df_data.to_csv(os.path.join(save_path,'data.csv'))\n",
    "        df_data.to_pickle(os.path.join(save_path,'data.pkl'))\n",
    "        df_epochs = nwbfile_zarr.stimulus['epochs'].to_dataframe()\n",
    "        df_photostim = nwbfile_zarr.stimulus['photostim'].to_dataframe()\n",
    "        df_visualstim = nwbfile_zarr.stimulus['visualstim'].to_dataframe()\n",
    "        #df_photostim.to_csv(os.path.join(save_path,'photostim.csv'))\n",
    "        #df_epochs.to_csv(os.path.join(save_path,'epochs.csv'))\n",
    "        #df_visualstim.to_csv(os.path.join(save_path,'visualstim.csv'))\n",
    "        df_data.to_pickle(os.path.join(save_path,'data.pkl'))\n",
    "        df_epochs.to_pickle(os.path.join(save_path,'epochs.pkl'))\n",
    "        df_photostim.to_pickle(os.path.join(save_path,'photostim.pkl'))\n",
    "        df_visualstim.to_pickle(os.path.join(save_path,'visualstim.pkl'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(session_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainsformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
